{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f3d9a2",
   "metadata": {},
   "source": [
    "## Fine tuning VGG16, VGG19 and ResNetRS101 for Human Activity Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f98fd2",
   "metadata": {},
   "source": [
    "### Group: 11 - Darshan Avaiya | Yukta Patel | Vaibhav Sheth | Taranjot Singh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5fbfbf",
   "metadata": {},
   "source": [
    "### Professor - Ran Feldesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2a77e",
   "metadata": {},
   "source": [
    "Date - August 6, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027391b2",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a264e3",
   "metadata": {},
   "source": [
    "The aim of this project is to fine tune three CNN models for human activity classification. The project utilizes popular pre-trained models such as VGG16, VGG19, and ResNet101 to achieve high prediction accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d01957",
   "metadata": {},
   "source": [
    "The project involves preprocessing input images to match the input size required by the models. The chosen model is loaded and fine-tuned for the specific image classification task. The models' architectures are adjusted by freezing certain layers to prevent overfitting. Additionally, techniques such as dropout and regularization are employed to enhance the models' generalization capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac7ce5",
   "metadata": {},
   "source": [
    "The Human Activity Recognition (HAR) dataset used for training and evaluation consists of labeled images belonging to different classes. The models are trained on a subset of the dataset and validated on another subset. Dataset contations 15 different classes presenting various human activities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bed066",
   "metadata": {},
   "source": [
    "The project's report highlights the technical aspects of implementing deep learning models, including model selection, architecture, preprocessing, and training. It emphasizes the results achieved through experimentation and provides insights into the challenges and solutions encountered during the project. By focusing on accurate image classification using deep learning, this project contributes to the broader field of computer vision and pattern recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551a651",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abd9821",
   "metadata": {},
   "source": [
    "In the field of computer vision and artificial intelligence, image classification stands as a fundamental task with wide range of applications. Accurate and automated recognition of objects and activities within images is important for numerous domains, including healthcare, surveillance, and entertainment. The Image Classification Project seeks to address this task through the implementation of cutting-edge deep learning techniques, leveraging well-established pre-trained models such as VGG16, VGG19, and ResNetRS101."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa2826",
   "metadata": {},
   "source": [
    "The primary objective of this project is to develop robust and accurate models capable of classifying human activities into various predefined categories. The project's focus lies in understanding the training process of these deep learning models, their adaptation for the given dataset, and the effective implementation of image classification methodologies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f6170",
   "metadata": {},
   "source": [
    "The core problem addressed in this project is Human Activity Recognition (HAR) using image classification techniques. HAR involves the identification and categorization of different human activities based on images. The goal is to develop a deep learning model capable of accurately classifying images into predefined categories that correspond to various human activities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8427d",
   "metadata": {},
   "source": [
    "Human Activity Recognition (HAR) through image classification holds significant importance due to its wide-ranging applications and potential benefits in various domains such as healthcare, fitness and sports, survelliance and security, industrial safety and many more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b322e",
   "metadata": {},
   "source": [
    "## Related work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d2274",
   "metadata": {},
   "source": [
    "In the domain of Human Activity Recognition (HAR) and image classification, several prior works have laid the foundation for your project by exploring similar problems, methodologies, and challenges. Here are some examples of related work in this domain:\n",
    "\n",
    "1. \"Deep Convolutional Neural Networks for Human Activity Recognition Using Mobile Sensors\" (2015): This paper introduced the concept of using deep convolutional neural networks (CNNs) for HAR using sensor data from mobile devices. While not focused on images, it paved the way for applying deep learning to HAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33981a26",
   "metadata": {},
   "source": [
    "2. \"Human Activity Recognition: A Review\" (2019): This comprehensive review article summarizes the evolution of HAR techniques, including both traditional machine learning approaches and deep learning methods. It discusses datasets, features, and challenges in HAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb589b",
   "metadata": {},
   "source": [
    "3. \"Deep Learning-Based Human Activity Recognition: A Survey\" (2021): Another survey paper provides an up-to-date overview of deep learning techniques applied to HAR. It discusses various architectures, datasets, and challenges associated with training deep models for HAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf01fa4",
   "metadata": {},
   "source": [
    "4. Competitions and Challenges: Various data science competitions, such as Kaggle challenges, have provided platforms for researchers to showcase their HAR models. Studying winning solutions and approaches from such challenges can provide insights into effective strategies. Even dataset taken for this project is from a chellenge hosted by AI Planet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca26191",
   "metadata": {},
   "source": [
    "## Use Cases of Human Activity Classification/Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bce476",
   "metadata": {},
   "source": [
    "1. **Healthcare and Wellness Monitoring:** HAR can be utilized to monitor human activities for healthcare purposes. It can aid in tracking patient movements, identifying anomalies in daily activities, and ensuring the well-being of individuals, especially the elderly or those with medical conditions.\n",
    "<br>\n",
    "\n",
    "2. **Fitness and Sports Analysis:** HAR can be employed in fitness tracking and sports analysis. It enables the assessment of exercise routines, tracking of performance metrics, and providing personalized feedback to individuals aiming for physical fitness and athletic excellence.\n",
    "<br>\n",
    "\n",
    "3. **Surveillance and Security:** HAR is crucial for security and surveillance applications. It can assist in identifying suspicious or abnormal activities in public spaces, ensuring public safety, and enhancing security measures.\n",
    "<br>\n",
    "\n",
    "4. **Industrial Safety:** In industrial settings, HAR can be used to monitor worker activities and ensure compliance with safety protocols. It helps prevent accidents and provides insights into optimizing workflow efficiency.\n",
    "<br>\n",
    "\n",
    "5. **Behavioral Analysis:** HAR aids in understanding human behavior and patterns. This is valuable in fields like psychology, sociology, and market research, enabling researchers to gather insights into daily routines and habits.\n",
    "<br>\n",
    "\n",
    "6. **Automated Processes:** In automation and robotics, HAR contributes to creating smarter systems that can react appropriately to human actions. This is essential in scenarios like industrial automation, robot-human collaboration, and autonomous vehicles.\n",
    "<br>\n",
    "\n",
    "7. **Smart Environments:** HAR contributes to the development of smart environments that respond intelligently to human presence and actions. This includes energy-efficient lighting, climate control, and home automation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5b142",
   "metadata": {},
   "source": [
    "## Introduction to Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360dad5",
   "metadata": {},
   "source": [
    "The dataset used in this project is collected from the Data Sprint 76 - Human Activity Recognition challenge provided by Aiplanet. It comprises a diverse collection of images capturing human activities, each associated with specific labels that denote the corresponding activity. The dataset is structured to enable supervised learning, where images are the input features, and the activity labels serve as the ground truth for model training and assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ff146",
   "metadata": {},
   "source": [
    "Dataset includes a train and test folders including images and a csv file containing training images names and associated lables with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3843458b",
   "metadata": {},
   "source": [
    "While performing data preprocessing steps, image size was reduced to 120x120 according to computational capacity. Images were converted into numpy array and labels were encoded in one-hot vector to train models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3e56c",
   "metadata": {},
   "source": [
    "Training data was splitted into two parts. 70% dataset for training purpose and 30% of data was preparedfor model validation purpose. Stratified train validation splitting was used to maintain the balance in classes of human activities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa0da5d",
   "metadata": {},
   "source": [
    "**Data Augmentation:** To increase diversity and control overfitting, following data augmentation was applied on training set.\n",
    "data augmentation can be understood as follows:\n",
    "\n",
    "1. **Rotation:** The images are rotated by a certain angle (up to the specified rotation range). This helps the model become invariant to different orientations of the activities.\n",
    "<br>\n",
    "\n",
    "2. **Shift:** Images are shifted horizontally and vertically within a specified range. This simulates variations in camera angles and positioning.\n",
    "<br>\n",
    "3. **Shear:** Shearing involves shifting one part of an image in a specific direction while keeping the other part fixed. This can simulate different viewpoints.\n",
    "<br>\n",
    "4. **Zoom:** Images can be zoomed in or out, mimicking scenarios where the camera captures activities from different distances.\n",
    "<br>\n",
    "5. **Horizontal Flip:** Images are flipped horizontally. This is particularly useful when the orientation of the activity doesn't impact its classification.\n",
    "<br>\n",
    "6. **Fill Mode:** This specifies how to fill in the gaps created by transformations like rotation or shifting. The 'nearest' mode fills gaps with the nearest pixel values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa16440",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae285dcb",
   "metadata": {},
   "source": [
    "Three models were trained using Tensorflow framework of Python:\n",
    "<br>\n",
    "1. VGG16\n",
    "2. VGG19\n",
    "2. ResNetRS101\n",
    "<br>\n",
    "\n",
    "Weights of top layers were freezed and few layers were added as top layers on architecture of above models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf962cf2",
   "metadata": {},
   "source": [
    "Top layers of all models were as per below:\n",
    "<br>\n",
    "\n",
    "model.add(Flatten())\n",
    "<br>\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "<br>\n",
    "model.add(Dropout(0.5))\n",
    "<br>\n",
    "model.add(Dense(15, activation=\"softmax\"))\n",
    "<br>\n",
    "\n",
    "20 epochs were used to train models with \"adam\" optimizer, \"categorical_crossentropy\" as a loss function and \"accuracy\" as evaluation metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
